---
layout: default
---
# Resume

[LinkedIn](https://www.linkedin.com/in/christopher-johnson/)

Data geek, leader, problem solver, and critical thinker. Ability to work alone or collaborate with anyone across an organization. Experienced with setting up automation, cleaning data sets, creating data-driven business solutions, and analytics from said data sets. Comfortable presenting and explaining analytic solutions to a single individual or a large group.

## Skills

|         |          | |
|:-------------|:------------------|:------------------|
| Python       | KPI Development   | Project Management|
| SQL          | AWS Environments  | ETL/ELT Development|
| Tableau      | Decision Analytics| BI Data Engineering|


## Projects

-	[Golf Score Collection and Analytics](https://github.com/CBJohnson30/Golf-Scores) 
    -  Built out a process to collect, store, and analyze my results from my golf rounds. Course information and round performance data are collected using Python widgets and stored in a Postgres database.
-	[Voter Registrations](https://github.com/CBJohnson30/Colorado-Voter-Registration)
    - Used unsupervised learning, time series techniques, and visualizations to forecast voter registration and analyze how election results impact voter registration numbers.
-	[NCAA Basketball](https://github.com/CBJohnson30/NCAA-Basketball-2018)
    - Used machine learning to predict the NCAA men’s basketball tournament. Participated in a sponsored Kaggle Competition.
-	[Global Terrorism](https://github.com/CBJohnson30/Global-Terrorism)
    - Used Bayesian techniques to make inferences and predictions on global terrorism data.


## Work Experience

### Data Analyst, _Viasat_
October 2021 - August 2025
-	Developed Tableau dashboards for key operational verticals, including purchasing, supply/demand planning, manufacturing, depot, and logistics, increasing data visibility and actionable insights.
-	Built Tableau dashboards for full life cycle multi-level Bill of Material Clear to Build, multi-platform Purchase Order status, and defining program health projections saving 10+ hours a week in manual Excel report building. 
-	Improved the team's Jira ticketing process to give the team a clearer standard to set priority for new features, tasks, and bugs. Set up dashboards to monitor the current, future, and past workload of the team allowing leadership to gain insight into our impact and workload resulting in conversations with leadership to increase team bandwidth and scope adjustments.
-	Directed and oversaw the transition of the team's ETL pipelines from legacy systems to the new data lake, resulting in securitized data and increased refresh times for specialized data sets.
-	Performed a Tableau migration from commercial cloud to an AWS Gov cloud environment with minimal impact on our Tableau dashboards for our customers. Used Tableau add-ons to help secure the migration would go as planned. Leading to an increase in security for our dashboards and access to more secured data.

### Data Conversion Engineer, _CentralSquare Technologies_
February 2021 - April 2021
-	Converted legacy data into a new data format for various products. Worked with internal SMEs to quickly understand the product's capabilities and needs. While also, working with clients and product managers to fulfill the statement of work and the client's needs. Created data conversions using SQL.

### Data Analyst, _Shaw Communications_
April 2020 - August 2020
-	Designed and developed an ETL process from Snowflake into AWS Elastic Search and Dynamo. Optimized ETL pipelines to run under the 20-minute update window. 
-	Compiled and understood different business logic from multiple parts of Shaw Communications to fill the new Unified Customer Portal.

### ETL Developer, _Appriss_
December 2018 - April 2020
-	Worked with internal groups to create or improve ETL/ELT processes. These projects focused on automation, monitoring, and improving accuracy. Created an automatic Kanban ticking system to keep the team organized and notified of upcoming work. 
-	Through detailed requirement gathering, designed and filled a “Master Source” database to create reports used by our product and accusations team to help fill in holes and reduce overlaps in the company’s data. 
-	Created person-to-event matching logic that reduced data storage by 20%, reduced runtime in API calls, and increased the accuracy of possible matches. 
-	Worked with clients to inject, transform, normalize, and return their marketing data in an ad hoc environment. 

### Data Science Immersive Program, _General Assembly_
January 2018 – April 2018
-	A 12-week long Data Science Program that fully immersed students into advanced data science techniques and practices. Creating and cleaning data to use for data-driven analysis using predictive modeling and hypothesis testing. 
-	Topics included; statistical A/B testing, Git, regression and classification models, data mining, data visualizations, ETL pipelines, unsupervised learning, natural language processing, decision trees, ensemble and boosting methods, neural networks, time series analysis, Bayesian analysis, Hadoop eco-systems, AWS cloud computing, and technical presenting. 


## Education

### California State University San Marcos - _San Marcos, Califorina_
Fall 2025 - Present
- Masters of Science in Supply Chain Analytics

### General Assembly - _Denver, Colorado_
2018
- Data Science Immersive Program (DSI)

### Oregon State University - _Corvallis, Oregon_
Fall 2010 - Fall 2015
-	Bachelor of Science, Economics: Option in Managerial Economics and Public Economics.


